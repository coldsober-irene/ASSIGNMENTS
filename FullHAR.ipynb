{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7zG0b+/r65cp97RBkUYZC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coldsober-irene/ASSIGNMENTS/blob/main/FullHAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##combined codes"
      ],
      "metadata": {
        "id": "m2CzbuJoQhbn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGVc_GIPQgYo",
        "outputId": "e2d01f58-a339-4236-e629-b6335272cad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.svm import SVC\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "samples = 20\n",
        "rate = 7\n",
        "\n",
        "class Sampling:\n",
        "  count = 0\n",
        "  def __init__(self, video_path, map_file, sampling_type = 'uniform', val_sampling = False,\n",
        "               ref_mean=[0.07, 0.07, 0.07], ref_std=[0.1, 0.09, 0.08], enhance_img = False, **kwargs):\n",
        "    \"\"\"save_feature_dir: path for storing extracted features for future use\"\"\"\n",
        "    self.data_path = video_path\n",
        "    self.map_file = map_file\n",
        "    self.sampling_type = sampling_type\n",
        "    self.is_valSampling = val_sampling\n",
        "    self.mean = ref_mean\n",
        "    self.std = ref_std\n",
        "    self.enhance_img = enhance_img\n",
        "    # ALL FEATURES OBTAINED FROM ENTIRE DATASETS\n",
        "    self.obtained_features = []\n",
        "    self.labels = []\n",
        "\n",
        "    # GETTING MAPPING\n",
        "    self.maps = {}\n",
        "    with open(self.map_file, 'r') as f:\n",
        "      lines = f.readlines()\n",
        "      for line in lines:\n",
        "          parts = line.split()\n",
        "          if self.is_valSampling:\n",
        "            self.maps[parts[-1]] = int(parts[1])\n",
        "          else:\n",
        "            self.maps[parts[1]] = int(parts[0])\n",
        "    print(f'mapping: {self.maps}')\n",
        "    # SAMPLERS\n",
        "    self.TrainD_sampler = self.Sampling_Training(data_path = self.data_path,\n",
        "                                                 mapping = self.maps,\n",
        "                                                 labels_list = self.labels)\n",
        "    self.ValidationD_sampler = self.Sampling_Validation(data_path = self.data_path,\n",
        "                                                        mapping = self.maps,\n",
        "                                                labels_list = self.labels )\n",
        "\n",
        "    # FRAME SAMPLING\n",
        "    if val_sampling:\n",
        "      self.ValidationD_sampler.Sample(sampling_processor = self.sample)\n",
        "    else:\n",
        "      self.TrainD_sampler.Sample(sampling_processor = self.sample)\n",
        "\n",
        "\n",
        "    # SAVE EXTRACTED FEATURE INTO THE FILE FOR FUTURE USE\n",
        "    self.saveFeatures(destination_dir = kwargs['save_feature_dir'])\n",
        "    print(\"EXTRACTED FEATURE ARE SAVED SUCCESSFULLY!\")\n",
        "\n",
        "  def UniformSampling(self, cap, sample_rate, frameCount):\n",
        "    for i in range(0, frameCount, sample_rate):\n",
        "      cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "      ret, frame = cap.read()\n",
        "      if ret:\n",
        "        if self.enhance_img:\n",
        "          return self.enhance_image(input_frame = frame)\n",
        "        return frame\n",
        "\n",
        "  def RandomSampling(self, cap,num_samples, frameCount):\n",
        "    sampled_indices = random.sample(range(frameCount), num_samples)\n",
        "\n",
        "    for i in sampled_indices:\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "        ret, frame = cap.read()\n",
        "        if ret:\n",
        "          if self.enhance_img:\n",
        "            return self.enhance_image(input_frame = frame)\n",
        "          return frame\n",
        "\n",
        "  def sample(self, cap, **kwargs):\n",
        "    # CREATE EXTRACTOR OBJECT\n",
        "    Extractor = Feature_extract(sampled_type = self.sampling_type)\n",
        "    Sampling.count += 1\n",
        "    if self.sampling_type == 'uniform':\n",
        "      sample_frame = self.UniformSampling(cap = cap, frameCount=kwargs['frame_count'], sample_rate = kwargs['sample_rate'])\n",
        "      kwargs['frames_sampled'].append(sample_frame)\n",
        "\n",
        "    elif self.sampling_type == 'random':\n",
        "      sample_frame = self.RandomSampling(cap = cap, frameCount=kwargs['frame_count'], num_samples=kwargs['num_samples'])\n",
        "      kwargs['frames_sampled'].append(sample_frame)\n",
        "\n",
        "    # EXTRACT FEATURE FROM THE FRAMES OF EACH VIDEO\n",
        "    features_obtained = Extractor.features(frames = kwargs['frames_sampled'], ref_mean = self.mean, ref_std = self.std)\n",
        "    self.obtained_features.append(features_obtained)\n",
        "    print('Constructor created!')\n",
        "\n",
        "  def enhance_image(self, input_frame, gamma=0.35, kernel_size=3):\n",
        "    # Apply gamma correction\n",
        "    gamma_corrected = np.power(input_frame / 255.0, gamma) * 255.0\n",
        "    gamma_corrected = gamma_corrected.astype(np.uint8)\n",
        "\n",
        "    # Return the gamma_corrected image\n",
        "    return gamma_corrected\n",
        "    print(\"FEATURE EXTRACTION AND SAVING IS DONE!!!\")\n",
        "\n",
        "  def saveFeatures(self, destination_dir):\n",
        "    # CREATE VSTACK ARRAY OF ALL FEATURES EXTRACTED\n",
        "    all_features = np.vstack(self.obtained_features)\n",
        "    labels = np.array(self.labels)\n",
        "\n",
        "    # SAVED THE EXTRACTED FEATURES and their corresponding labels FOR FUTURE USE\n",
        "    os.makedirs(destination_dir, exist_ok = True)\n",
        "\n",
        "    np.save(os.path.join(destination_dir,f'features{Sampling.count}.npy'), all_features)\n",
        "    np.save(os.path.join(destination_dir,f'labels{Sampling.count}.npy'), labels)\n",
        "\n",
        "\n",
        "  class Sampling_Training:\n",
        "    def __init__(self, data_path, mapping:dict, labels_list:list = None):\n",
        "      self.data_path = data_path\n",
        "      self.maps = mapping\n",
        "      # subfolders\n",
        "      self.activities = os.listdir(self.data_path)\n",
        "      # EXTRACTED FEATURES FROM ALL THE VIDEOS\n",
        "      self.obtained_features = []\n",
        "      # LABELS OF THE EXTRACTED FEATURES\n",
        "      self.labels_list = labels_list\n",
        "\n",
        "    def Sample(self,sampling_processor, sample_rate = 5, num_samples = 10):\n",
        "      # Loop through each activity\n",
        "      for activity in self.activities:\n",
        "          activity_folder = os.path.join(self.data_path, activity)\n",
        "\n",
        "          # Loop through video files in the activity folder\n",
        "          for video_file in os.listdir(activity_folder):\n",
        "            if '.mp4' in video_file:\n",
        "              frames_sampled = []\n",
        "              video_path = os.path.join(activity_folder, video_file)\n",
        "              cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "              frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "              # PROCESSOR FOR FINISHING THE TASK\n",
        "              sampling_processor(frame_count = frame_count,\n",
        "                  sample_rate = sample_rate, frames_sampled = frames_sampled\n",
        "                                 , num_samples = num_samples)\n",
        "              # POPULATE THE LABEL CORRESPONDING TO THE CURRENT VIDEO\n",
        "              if self.labels_list:\n",
        "                self.labels_list.append(self.maps[activity])\n",
        "\n",
        "  class Sampling_Validation:\n",
        "    def __init__(self, data_path,mapping:dict, labels_list:list = None):\n",
        "      self.data_path = data_path\n",
        "      self.maps = mapping\n",
        "      self.labels_list = labels_list\n",
        "\n",
        "    def Sample(self, sampling_processor, sample_rate = 5, num_samples = 10):\n",
        "      'sampling_processor: object to make sampling'\n",
        "      # Loop through video files in the activity folder\n",
        "      for video_file in os.listdir(self.data_path):\n",
        "        if '.mp4' in video_file:\n",
        "          frames_sampled = []\n",
        "          video_path = os.path.join(self.data_path, video_file)\n",
        "          cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "          frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "          # PROCESSOR FOR FINISHING THE TASK\n",
        "          sampling_processor(cap = cap, frame_count = frame_count,\n",
        "            sample_rate = sample_rate, frames_sampled = frames_sampled,\n",
        "                             num_samples = num_samples)\n",
        "          # POPULATE THE LABEL CORRESPONDING TO THE CURRENT VIDEO\n",
        "          self.labels_list.append(self.maps[video_file])\n",
        "\n",
        "class Feature_extract:\n",
        "  def __init__(self, sampled_type = 'uniform'):\n",
        "    # Load pre-trained ResNet50\n",
        "    self.model = ResNet50(weights='imagenet', include_top=False)\n",
        "    self.sampled_type = sampled_type\n",
        "\n",
        "  # Function to normalize a frame\n",
        "  def normalize_frame(self, frame, ref_mean, ref_std):\n",
        "      actual_mean = np.mean(frame, axis=(0, 1), keepdims=True)\n",
        "      actual_std = np.std(frame, axis=(0, 1))\n",
        "      normalized_frame = (frame - actual_mean) / actual_std * ref_std + ref_mean\n",
        "      return normalized_frame\n",
        "\n",
        "  # Function to preprocess frames and extract features using ResNet\n",
        "  def features(self,frames, ref_mean, ref_std):\n",
        "      processed_frames = [self.normalize_frame(frame, ref_mean, ref_std) for frame in frames]\n",
        "      processed_frames = [preprocess_input(frame) for frame in processed_frames]\n",
        "      features = self.model.predict(np.array(processed_frames))\n",
        "      return features\n",
        "\n",
        "class Train_model:\n",
        "  def __init__(self, valid_features_dir, train_features_dir, feaures_base_names = [], labels_base_name = [], **kwargs):\n",
        "    '''kwargs: [val_size ex: 0.2, num_classes: classes of dataset, epoch ex : 200, patience: ex: 10, model_storage_dir: dir to hold trained model]'''\n",
        "    self.trainFeatures = os.path.join(train_features_dir, feaures_base_names[0])\n",
        "    self.valFeatures = os.path.join(valid_features_dir, feaures_base_names[1])\n",
        "    self.trainLabels = os.path.join(train_features_dir, labels_base_name[0])\n",
        "    self.valLabels = os.path.join(valid_features_dir, labels_base_name[1])\n",
        "    #'/content/drive/MyDrive/machine vision assignment 2/EE6222 train and validate 2023/train/features/features1.npy'\n",
        "    # labels_dir = '/content/drive/MyDrive/machine vision assignment 2/EE6222 train and validate 2023/train/features/labels1.npy'\n",
        "    # val_features = '/content/drive/MyDrive/machine vision assignment 2/EE6222 train and validate 2023/validate/features/features1.npy'\n",
        "    # val_labels = '/content/drive/MyDrive/machine vision assignment 2/EE6222 train and validate 2023/validate/features/labels1.npy'\n",
        "    self.X_train = np.load(self.trainFeatures, allow_pickle = True)\n",
        "    self.y_train = np.load(self.trainLabels, allow_pickle = True)\n",
        "    self.X_val = np.load(self.valFeatures, allow_pickle = True)\n",
        "    self.y_val = np.load(self.valLabels, allow_pickle = True)\n",
        "\n",
        "    self.kwargs = kwargs\n",
        "    self.val_size = self.kwargs['val_size'] # 0.64\n",
        "    self.shuffle = True\n",
        "    self.num_classes = self.kwargs['num_classes'] #6\n",
        "    self.epoch = self.kwargs['epoch'] #300\n",
        "    self.patience = self.kwargs['patience'] # 10\n",
        "    self.early_stopping = EarlyStopping(monitor='val_loss', patience= self.patience)\n",
        "\n",
        "    features = np.vstack([self.X_train, self.X_val])\n",
        "    labels = np.hstack([self.y_train, self.y_val])\n",
        "    # print(labels.shape)\n",
        "    self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(features, labels, test_size=self.val_size,\n",
        "                                                                          shuffle = self.shuffle, random_state=42)\n",
        "    # DIR FOR MODEL\n",
        "    # BASE_DIR ='/content/drive/MyDrive/machine vision assignment 2/EE6222 train and validate 2023/models'\n",
        "    os.makedirs(kwargs['model_storage_dir'], exist_ok = True)\n",
        "\n",
        "  def trainModel(self, model_savename = 'uniform_model'):\n",
        "    # Define the model with 3D convolutional layers\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=self.X_train.shape[1:]),  # Input shape matches your feature shape\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(self.num_classes, activation='softmax')  # Output layer with the number of classes\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    modelHistory = model.fit(self.X_train, self.y_train, epochs=self.epoch, validation_data=(self.X_val, self.y_val)) # , callbacks=[early_stopping]\n",
        "    plotting(modelHistory)\n",
        "    model.save(os.path.join(self.kwargs['model_storage_dir'],f'{model_savename}.h5'))\n",
        "\n",
        "    # PLOTTING\n",
        "    self.plotting(model)\n",
        "\n",
        "  def model_evaluation(self, val_features, val_labels):\n",
        "    results = {}\n",
        "    X_val = np.load(val_features, allow_pickle = True)\n",
        "    y_val = np.load(val_labels, allow_pickle = True)\n",
        "    BASE_DIR = self.kwargs['model_storage_dir']\n",
        "    models = os.listdir(BASE_DIR)\n",
        "    # Load your saved model\n",
        "    model = keras.models.load_model(os.path.join(BASE_DIR, f'{k.split()[0]}_model.h5'))\n",
        "    # Evaluate the model on the test data\n",
        "    test_loss, test_accuracy = model.evaluate(X_val, y_val)\n",
        "\n",
        "    # Print the evaluation results\n",
        "\n",
        "    print(\"enhanced images sample\")\n",
        "    print(\"-\"*100)\n",
        "    print(f'Test Loss: {test_loss}')\n",
        "    print(f'Test Accuracy: {test_accuracy}')\n",
        "    results['test'] = (test_loss, test_accuracy)\n",
        "    # RESULTS DATAFRAME\n",
        "    result_df = pd.DataFrame(results)\n",
        "    print(result_df)\n",
        "    return result_df.to_latex(index=False)\n",
        "\n",
        "def plotting(model):\n",
        "  # Access training history\n",
        "  training_accuracy = model.history['accuracy']\n",
        "  validation_accuracy = model.history['val_accuracy']\n",
        "  training_loss = model.history['loss']\n",
        "  validation_loss = model.history['val_loss']\n",
        "  # Plot the training and validation accuracy\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.plot(training_accuracy, label='Training Accuracy')\n",
        "  plt.plot(validation_accuracy, label='Validation Accuracy')\n",
        "  plt.plot(training_loss, label='Training loss')\n",
        "  plt.plot(validation_loss, label='Validation loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.title('Training and Validation')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "  plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#object construction"
      ],
      "metadata": {
        "id": "uozieIbBPRNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map_file = '/content/drive/MyDrive/machine vision assignment 2/EE6222 train and validate 2023/validate.txt'\n",
        "samp = Sampling(video_path = '/content/drive/MyDrive/dummy',\n",
        "                map_file = map_file,\n",
        "                sampling_type='random',\n",
        "                val_sampling = True,\n",
        "                ref_mean=[0.07, 0.07, 0.07],\n",
        "                ref_std=[0.1, 0.09, 0.08],\n",
        "                save_feature_dir = '/content/drive/MyDrive/dummy')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rp2xoLAuPV96",
        "outputId": "2cafda30-8c7e-4e6e-ac30-098ab8918262"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mapping: {'24.mp4': 0, '25.mp4': 0, '26.mp4': 0, '27.mp4': 0, '28.mp4': 0, '29.mp4': 0, '30.mp4': 0, '31.mp4': 0, '32.mp4': 0, '33.mp4': 0, '34.mp4': 0, '35.mp4': 0, '36.mp4': 0, '37.mp4': 0, '38.mp4': 0, '39.mp4': 0, '40.mp4': 0, '176.mp4': 1, '177.mp4': 1, '178.mp4': 1, '179.mp4': 1, '180.mp4': 1, '181.mp4': 1, '182.mp4': 1, '183.mp4': 1, '184.mp4': 1, '185.mp4': 1, '186.mp4': 1, '187.mp4': 1, '188.mp4': 1, '189.mp4': 1, '190.mp4': 1, '202.mp4': 2, '203.mp4': 2, '204.mp4': 2, '205.mp4': 2, '206.mp4': 2, '207.mp4': 2, '208.mp4': 2, '209.mp4': 2, '210.mp4': 2, '211.mp4': 2, '212.mp4': 2, '213.mp4': 2, '214.mp4': 2, '215.mp4': 2, '216.mp4': 2, '235.mp4': 3, '236.mp4': 3, '237.mp4': 3, '238.mp4': 3, '239.mp4': 3, '240.mp4': 3, '241.mp4': 3, '242.mp4': 3, '243.mp4': 3, '244.mp4': 3, '245.mp4': 3, '246.mp4': 3, '247.mp4': 3, '248.mp4': 3, '249.mp4': 3, '250.mp4': 3, '267.mp4': 4, '268.mp4': 4, '269.mp4': 4, '270.mp4': 4, '271.mp4': 4, '272.mp4': 4, '273.mp4': 4, '274.mp4': 4, '275.mp4': 4, '276.mp4': 4, '277.mp4': 4, '278.mp4': 4, '279.mp4': 4, '280.mp4': 4, '281.mp4': 4, '282.mp4': 4, '283.mp4': 4, '295.mp4': 5, '296.mp4': 5, '297.mp4': 5, '298.mp4': 5, '299.mp4': 5, '300.mp4': 5, '301.mp4': 5, '302.mp4': 5, '303.mp4': 5, '304.mp4': 5, '305.mp4': 5, '306.mp4': 5, '307.mp4': 5, '308.mp4': 5, '309.mp4': 5, '310.mp4': 5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ab8a0200b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Constructor created!\n",
            "EXTRACTED FEATURE ARE SAVED SUCCESSFULLY!\n"
          ]
        }
      ]
    }
  ]
}